{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c15c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu128)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.0.0)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.121.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting uvicorn[standard]\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Collecting click>=7.0 (from uvicorn[standard])\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (0.16.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
      "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard])\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (6.0.3)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard])\n",
      "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Downloading fastapi-0.121.3-py3-none-any.whl (109 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Installing collected packages: websockets, uvloop, typing-inspection, python-dotenv, pydantic-core, httptools, click, annotated-types, annotated-doc, watchfiles, uvicorn, starlette, pydantic, fastapi\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [fastapi]2/14\u001b[0m [pydantic]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-doc-0.0.4 annotated-types-0.7.0 click-8.3.1 fastapi-0.121.3 httptools-0.7.1 pydantic-2.12.4 pydantic-core-2.41.5 python-dotenv-1.2.1 starlette-0.50.0 typing-inspection-0.4.2 uvicorn-0.38.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124  # adjust CUDA version\n",
    "!pip install pillow fastapi uvicorn[standard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6dd972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['siberian_husky', 'silky_terrier', 'scottish_deerhound', 'saint_bernard', 'yorkshire_terrier']\n",
      "siberian_husky -> 66 train, 14 val, 15 test\n",
      "silky_terrier -> 62 train, 13 val, 15 test\n",
      "scottish_deerhound -> 88 train, 18 val, 20 test\n",
      "saint_bernard -> 58 train, 12 val, 14 test\n",
      "yorkshire_terrier -> 57 train, 12 val, 13 test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "DATA_ROOT = Path(\"/workspace/dog/Mini_Dog_Breed_Data\")   # original folder with 5 subfolders\n",
    "OUT_ROOT = Path(\"data_split\")           # will be created: train/val/test/...\n",
    "\n",
    "SPLIT_RATIOS = {\n",
    "    \"train\": 0.7,\n",
    "    \"val\": 0.15,\n",
    "    \"test\": 0.15,\n",
    "}\n",
    "\n",
    "def main():\n",
    "    assert abs(sum(SPLIT_RATIOS.values()) - 1.0) < 1e-6\n",
    "\n",
    "    classes = [d for d in DATA_ROOT.iterdir() if d.is_dir()]\n",
    "    print(\"Classes:\", [c.name for c in classes])\n",
    "\n",
    "    for split in SPLIT_RATIOS.keys():\n",
    "        for cls in classes:\n",
    "            (OUT_ROOT / split / cls.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for cls in classes:\n",
    "        images = [p for p in cls.iterdir() if p.is_file()]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        n = len(images)\n",
    "        n_train = int(n * SPLIT_RATIOS[\"train\"])\n",
    "        n_val   = int(n * SPLIT_RATIOS[\"val\"])\n",
    "        # rest go to test\n",
    "        n_test  = n - n_train - n_val\n",
    "\n",
    "        split_map = {\n",
    "            \"train\": images[:n_train],\n",
    "            \"val\":   images[n_train:n_train + n_val],\n",
    "            \"test\":  images[n_train + n_val:],\n",
    "        }\n",
    "\n",
    "        for split, imgs in split_map.items():\n",
    "            for img in imgs:\n",
    "                dst = OUT_ROOT / split / cls.name / img.name\n",
    "                shutil.copy2(img, dst)\n",
    "\n",
    "        print(cls.name, \"->\", n_train, \"train,\", n_val, \"val,\", n_test, \"test\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9ecc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "--------------------\n",
      "train Loss: 1.4944 Acc: 0.4743\n",
      "val Loss: 1.1694 Acc: 0.7536\n",
      "** New best model saved (val acc = 0.7536) **\n",
      "\n",
      "Epoch 2/20\n",
      "--------------------\n",
      "train Loss: 1.0580 Acc: 0.7100\n",
      "val Loss: 0.4916 Acc: 0.8841\n",
      "** New best model saved (val acc = 0.8841) **\n",
      "\n",
      "Epoch 3/20\n",
      "--------------------\n",
      "train Loss: 0.6512 Acc: 0.8036\n",
      "val Loss: 0.2058 Acc: 0.9275\n",
      "** New best model saved (val acc = 0.9275) **\n",
      "\n",
      "Epoch 4/20\n",
      "--------------------\n",
      "train Loss: 0.4141 Acc: 0.8731\n",
      "val Loss: 0.1671 Acc: 0.9420\n",
      "** New best model saved (val acc = 0.9420) **\n",
      "\n",
      "Epoch 5/20\n",
      "--------------------\n",
      "train Loss: 0.4058 Acc: 0.8580\n",
      "val Loss: 0.1843 Acc: 0.9130\n",
      "\n",
      "Epoch 6/20\n",
      "--------------------\n",
      "train Loss: 0.4467 Acc: 0.8097\n",
      "val Loss: 0.1391 Acc: 0.9420\n",
      "\n",
      "Epoch 7/20\n",
      "--------------------\n",
      "train Loss: 0.3237 Acc: 0.8852\n",
      "val Loss: 0.1333 Acc: 0.9710\n",
      "** New best model saved (val acc = 0.9710) **\n",
      "\n",
      "Epoch 8/20\n",
      "--------------------\n",
      "train Loss: 0.3433 Acc: 0.8792\n",
      "val Loss: 0.1897 Acc: 0.8986\n",
      "\n",
      "Epoch 9/20\n",
      "--------------------\n",
      "train Loss: 0.2467 Acc: 0.9154\n",
      "val Loss: 0.1519 Acc: 0.9420\n",
      "\n",
      "Epoch 10/20\n",
      "--------------------\n",
      "train Loss: 0.2276 Acc: 0.9305\n",
      "val Loss: 0.3203 Acc: 0.8551\n",
      "\n",
      "Epoch 11/20\n",
      "--------------------\n",
      "train Loss: 0.2819 Acc: 0.9063\n",
      "val Loss: 0.2383 Acc: 0.9130\n",
      "\n",
      "Epoch 12/20\n",
      "--------------------\n",
      "train Loss: 0.2149 Acc: 0.9335\n",
      "val Loss: 0.2106 Acc: 0.8986\n",
      "\n",
      "Epoch 13/20\n",
      "--------------------\n",
      "train Loss: 0.2428 Acc: 0.9215\n",
      "val Loss: 0.1442 Acc: 0.9275\n",
      "\n",
      "Epoch 14/20\n",
      "--------------------\n",
      "train Loss: 0.2152 Acc: 0.9215\n",
      "val Loss: 0.1533 Acc: 0.9420\n",
      "\n",
      "Epoch 15/20\n",
      "--------------------\n",
      "train Loss: 0.2290 Acc: 0.9275\n",
      "val Loss: 0.1482 Acc: 0.9420\n",
      "\n",
      "Epoch 16/20\n",
      "--------------------\n",
      "train Loss: 0.2600 Acc: 0.9003\n",
      "val Loss: 0.1651 Acc: 0.9275\n",
      "\n",
      "Epoch 17/20\n",
      "--------------------\n",
      "train Loss: 0.2441 Acc: 0.8973\n",
      "val Loss: 0.1326 Acc: 0.9420\n",
      "\n",
      "Epoch 18/20\n",
      "--------------------\n",
      "train Loss: 0.2355 Acc: 0.9184\n",
      "val Loss: 0.1521 Acc: 0.9420\n",
      "\n",
      "Epoch 19/20\n",
      "--------------------\n",
      "train Loss: 0.2282 Acc: 0.9215\n",
      "val Loss: 0.1301 Acc: 0.9420\n",
      "\n",
      "Epoch 20/20\n",
      "--------------------\n",
      "train Loss: 0.2259 Acc: 0.9215\n",
      "val Loss: 0.1485 Acc: 0.9420\n",
      "\n",
      "Training complete. Best val acc: 0.9710\n",
      "Test accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "DATA_ROOT = Path(\"data_split\")\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"dog_breed_resnet50.pth\"\n",
    "\n",
    "def get_dataloaders():\n",
    "    # Standard ImageNet transforms + augmentations for train\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \"val\": transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \"test\": transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {\n",
    "        split: datasets.ImageFolder(DATA_ROOT / split, transform=data_transforms[split])\n",
    "        for split in [\"train\", \"val\", \"test\"]\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        split: DataLoader(image_datasets[split],\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=(split == \"train\"),\n",
    "                          num_workers=4)\n",
    "        for split in [\"train\", \"val\", \"test\"]\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {split: len(image_datasets[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "    class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "    return dataloaders, dataset_sizes, class_names\n",
    "\n",
    "def build_model(num_classes):\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    # Freeze all layers first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace final layer\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "\n",
    "    # Optionally unfreeze last few layers of backbone\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"layer4\" in name or \"fc\" in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Only train parameters that require grad\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=LR\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.1, patience=3\n",
    "    )\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double().item() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == \"val\":\n",
    "                scheduler.step(epoch_acc)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save({\n",
    "                        \"model_state_dict\": best_model_wts,\n",
    "                        \"class_names\": dataloaders[\"train\"].dataset.classes\n",
    "                    }, MODEL_PATH)\n",
    "                    print(f\"** New best model saved (val acc = {best_acc:.4f}) **\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f\"Training complete. Best val acc: {best_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def evaluate(model, dataloader, dataset_size):\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    acc = running_corrects.double().item() / dataset_size\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataloaders, dataset_sizes, class_names = get_dataloaders()\n",
    "    model = build_model(num_classes=len(class_names))\n",
    "    model = train_model(model, dataloaders, dataset_sizes, NUM_EPOCHS)\n",
    "    evaluate(model, dataloaders[\"test\"], dataset_sizes[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d466c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
